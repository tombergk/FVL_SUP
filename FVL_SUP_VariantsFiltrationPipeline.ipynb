{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Variant Filtration Pipeline for FVL_SUP project\n",
    "\n",
    "\n",
    "##Fastq files\n",
    "\n",
    "All generated fastq files have been deposited to the [NCBI Sequence Read Archive](http://www.ncbi.nlm.nih.gov/sra) (project accession number \\#PRJNA296481)\n",
    "\n",
    "\\#PRJNA296481 encompasses 32 whole exome sequencing experiments from 32 different mice representing 8 ENU suppressor lines: *MF5L*1, *MF5L*5, *MF5L*6, *MF5L*8, *MF5L*9, *MF5L*11, *MF5L*12, *MF5L*16.\n",
    "\n",
    "Current pipeline calls variants jointly from all 32 sequencing experiments, and then focuses on 8 mice representing each of the ENU suppressor lines: \\#SRR2473338, \\#SRR2473339, \\#SRR2473340, \\#SRR2473342, \\#SRR2473343, \\#SRR2473344, \\#SRR2473347, \\#SRR2473348. Details below!\n",
    "\n",
    "##Overview of variant calling pipeline\n",
    "\n",
    "Reference genome: Mus_musculus GRCm38 release 73, downloaded from Ensemble\n",
    "\n",
    "Used software: \n",
    "* bwa (version 0.7.5a-r405)\n",
    "* picard-tools (version 1.105)\n",
    "* GenomeAnalysisTK (version 2.6.5)\n",
    "\n",
    "Steps to obtain the .vcf files:\n",
    "1. bwa aln -q 15\n",
    " bwa sampe\n",
    "2. picard-tools/SortSam.jar SORT_ORDER=coordinate VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true\n",
    "3. picard-tools/MarkDuplicates.jar VALIDATION_STRINGENCY=SILENT REMOVE_DUPLICATES=true ASSUME_SORTED=true CREATE_INDEX=true\n",
    "4. GenomeAnalysisTK/GenomeAnalysisTK.jar -T RealignerTargetCreator\n",
    "5. GenomeAnalysisTK/GenomeAnalysisTK.jar -T IndelRealigner\n",
    "6. picard-tools/FixMateInformation.jar SORT_ORDER=coordinate VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true\n",
    "7. GenomeAnalysisTK/GenomeAnalysisTK.jar -T HaplotypeCaller -stand_call_conf 50.0 stand_emit_conf\n",
    "8. GenomeAnalysisTK/GenomeAnalysisTK.jar -T VariantAnnotator -A VariantType\n",
    "9. GenomeAnalysisTK/GenomeAnalysisTK.jar -T SelectVariants -selectType SNP \n",
    "10. GenomeAnalysisTK/GenomeAnalysisTK.jar -T SelectVariants -selectType INDEL\n",
    "11. GenomeAnalysisTK/GenomeAnalysisTK.jar -T VariantFiltration --variant SNP.vcf --filterExpression 'QD < 2.0 || MQ < 40.0 || FS > 60.0 || HaplotypeScore > 13.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0' --filterName 'FAIL'\n",
    "12. GenomeAnalysisTK/GenomeAnalysisTK.jar -T VariantFiltration --variant INDEL.vcf --filterExpression \"QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0 || InbreedingCoeff < -0.8\" --filterName FAILED\n",
    "\n",
    "_End result is two vcf files: SNP.vcf and INDEL.vcf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preparation and Annotation of called SNP.vcf and INDEL.vcf\n",
    "\n",
    "Details on Annovar version and reference sequence:\n",
    "\n",
    "1. $LastChangedDate: 2012-05-25\n",
    "2. annotate_variation.pl --buildver mm10 --downdb seq mousedb/mm10_seq\n",
    "_Downloading annotation database ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz ... OK_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UNIX commands:\n",
    "    \n",
    "grep '#CHROM' SNP.vcf > header.txt\n",
    "cat SNP.vcf INDEL.vcf | sort -k1n -k2n | grep -v '#' > merged.vcf\n",
    "\n",
    "convert2annovar.pl merged.vcf -format vcf4old -includeinfo > merged\n",
    "annotate_variation.pl merged --buildver mm10 /database/annovar/mousedb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Variant Filtration Pipeline\n",
    "\n",
    "Input files are Annovar output files 'merged.exonic_variant_function' and 'merged.variant_function'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import all necessary packages\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import vcf\n",
    "import subprocess\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformatAnnovar(FileName,Header):\n",
    "    '''reformatAnnovar will merge .exonic_variant_function and .variant_function\n",
    "    back into one vcf file while adding Annovar Annotation into the INFO column'''\n",
    "    \n",
    "    input1=open(FileName+'.variant_function','r')\n",
    "    input2=open(FileName+'.exonic_variant_function','r')\n",
    "    outfile=open(FileName+'_annot.vcf','w')\n",
    "    header=open(Header,'r').readline().rstrip()\n",
    "    rows=[]\n",
    "    exonic=dict()\n",
    "    \n",
    "    print(header,file=outfile)\n",
    "    \n",
    "    for line in input2:\n",
    "        line=line.strip()\n",
    "        row=line.split('\\t')\n",
    "        row[15]=row[15]+';AnnovarType='+'_'.join(row[1].split())+';AnnovarGene='+'_'.join(row[2].split())\n",
    "        new_line=row[8:len(row)]        \n",
    "        new_line='\\t'.join(new_line)\n",
    "        exonic[row[3]+'_'+row[4]]=new_line\n",
    "\n",
    "    for line in input1:\n",
    "        line=line.strip()\n",
    "        row=line.split('\\t')\n",
    "        \n",
    "        if row[2]+'_'+row[3] in exonic:\n",
    "            print(exonic[row[2]+'_'+row[3]],file=outfile)\n",
    "            continue\n",
    "        else:\n",
    "            row[14]=row[14]+';AnnovarType='+'_'.join(row[0].split())+';AnnovarGene='+'_'.join(row[1].split())\n",
    "            new_line=row[7:len(row)]\n",
    "            print('\\t'.join(new_line),file=outfile)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VariantDictionaryFromVcf(VCFfile):\n",
    "    '''This Function Takes the variants in a given VCF file\n",
    "    and returns them in a dictionary formatted as chr_pos as keys'''\n",
    "    input=open(VCFfile)\n",
    "    variants=dict()\n",
    "    for line in input:\n",
    "        if not line.startswith('#'):\n",
    "            row=line.rstrip().split('\\t')\n",
    "            variants[row[0]+'_'+row[1]]=0\n",
    "    \n",
    "    return variants        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I merge Annovar annotation files of the original 'merged.vcf' file into **'merged_annot.vcf'** file. 'merged_annot.vcf' file will be used for the downstream filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reformatAnnovar('merged','header.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Before filtering, I am creating a dictionary of all known C57BL/6J and 129/SvImJ SNPs necessary for one of the filtering steps! The .vcf files for these SNPs and INDELs (GRCm38) is downloaded from the [Mouse Genomes Project](http://www.sanger.ac.uk/resources/mouse/genomes/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMJ=VariantDictionaryFromVcf('../../../NBEAL2/IPYTHON/129_mm10_variants.vcf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before filtering the variants, I am extracting data for the 8 mice we are interested in this project and reorder them according to the MF5L lines:\n",
    "\n",
    "|MouseID|SRA Accession|Name in VCF|ENU Line|\n",
    "|-|-|-|-|\n",
    "|37201|\\#SRR2473340|214_461_47|MF5L1|\n",
    "|33902|\\#SRR2473347|214_461_52|MF5L5|\n",
    "|33877|\\#SRR2473338|214_461_46|MF5L6|\n",
    "|33590|\\#SRR2473344|214_461_51|MF5L8|\n",
    "|31424|\\#SRR2473343|214_461_50|MF5L9|\n",
    "|33501|\\#SRR2473342|214_461_49|MF5L11|\n",
    "|33460|\\#SRR2473340|214_461_48|MF5L12|\n",
    "|39044|\\#SRR2473348|214_461_52|MF5L16|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UNIX command:\n",
    "awk '{OFS=\"\\t\";print $1,$2,$3,$4,$5,$6,$7,$8,$9,$35,$40,$34,$39,$38,$37,$36,$41}' merged_annot.vcf > leiden8.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTER 1** from 'leiden8.vcf' to 'leiden8_filter1.vcf'\n",
    "\n",
    "This step will apply multiple quality filters to identify likely ENU induced mutations in the 8 different suppressor line mice. This includes the following filters:\n",
    "- variant has to be in heterozygous state\n",
    "- alt allele unique to each mouse compared to other sequenced suppressor mice\n",
    "- variant called in at least 50% of the mice (6) to be able to assess uniqueness\n",
    "- heterozygous call has to have at least 6 reads and an allele ratio between 1/2 and 2 for reads DB<=10 and between 1/3 and 3 for DB>10\n",
    "- variant does not overlap C57BL/6J and 129/SvImJ known SNPs\n",
    "\n",
    "output files are going to be separate for each suppressor line\n",
    "\n",
    "_Count of all variants entering this step, of variants removed by each filter, and of variants that passed all filters are printed to stdout_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tGATK\tshared\t<50%GT\tbadDP\t129var\tpassed\n",
      "7012855\t1598268\t5128174\t204821\t78116\t944\t2532\n",
      "MF5L1\tMF5L5\tMF5L6\tMF5L9\tMF5L10\tMF5L12\tMF5L13\tMF5L22\n",
      "291\t164\t393\t597\t288\t232\t240\t327\n"
     ]
    }
   ],
   "source": [
    "vcfFile = vcf.Reader( open('leiden8.vcf','r') )\n",
    "MF5L1 = vcf.Writer(open('MF5L1_filter1.vcf', 'w'), vcfFile)\n",
    "MF5L5 = vcf.Writer(open('MF5L5_filter1.vcf', 'w'), vcfFile)\n",
    "MF5L6 = vcf.Writer(open('MF5L6_filter1.vcf', 'w'), vcfFile)\n",
    "MF5L9 = vcf.Writer(open('MF5L9_filter1.vcf', 'w'), vcfFile)\n",
    "MF5L10 = vcf.Writer(open('MF5L10_filter1.vcf', 'w'), vcfFile)\n",
    "MF5L12 = vcf.Writer(open('MF5L12_filter1.vcf', 'w'), vcfFile)\n",
    "MF5L13 = vcf.Writer(open('MF5L13_filter1.vcf', 'w'), vcfFile)\n",
    "MF5L22 = vcf.Writer(open('MF5L22_filter1.vcf', 'w'), vcfFile)\n",
    "\n",
    "printIDs=[MF5L1,MF5L5,MF5L6,MF5L9,MF5L10,MF5L12,MF5L13,MF5L22]\n",
    "miceIDs=['214_461_47','214_461_52','214_461_46',\n",
    "         '214_461_51','214_461_50','214_461_49','214_461_48','214_461_53']\n",
    "\n",
    "#filters statistics\n",
    "counter=0\n",
    "(f1,f2,f3,f4,f5,passed)=(0,0,0,0,0,0)\n",
    "p=[0]*8\n",
    "\n",
    "for record in vcfFile:  \n",
    "    counter+=1    \n",
    "    \n",
    "    #remove variants that did not pass the GATK filters:\n",
    "    if not len(record.FILTER)==0:\n",
    "        f1+=1\n",
    "        continue\n",
    "    \n",
    "    #remove variants where there are more alleles as hets or homozygous calls:\n",
    "    if record.num_het > 1 or record.num_hom_alt > 0:\n",
    "        f2+=1\n",
    "        continue\n",
    "              \n",
    "    #remove variants where 50% of the mice (4 mice) have no genotype called      \n",
    "    if record.num_unknown>=4:\n",
    "        f3+=1\n",
    "        continue \n",
    "\n",
    "    #called '0/1' variant should have read depth of 6\n",
    "    #with allele ratios between 1/3 and 3 (1/2 and 2 for DP<=10):\n",
    "    \n",
    "    count_DP=0\n",
    "    for i in miceIDs:\n",
    "        if not record.genotype(i)==None and not record.genotype(i)['GT']==None:\n",
    "            if not record.genotype(i)['GT']=='0/1':\n",
    "                continue\n",
    "            if not hasattr(record.genotype(i).data,'DP'):\n",
    "                continue\n",
    "            if not record.genotype(i)['DP']==None: \n",
    "                if int(record.genotype(i)['DP'])>=6:\n",
    "                    ref=float(record.genotype(i)['AD'][0])\n",
    "                    alt=float(record.genotype(i)['AD'][1])\n",
    "                    \n",
    "                    if alt==0 or ref==0:\n",
    "                        continue \n",
    "                        \n",
    "                    dev=alt/ref\n",
    "                    \n",
    "                    if int(record.genotype(i)['DP'])<=10:\n",
    "                        if dev<0.5 or dev>2:\n",
    "                            continue\n",
    "                    if int(record.genotype(i)['DP'])>10:\n",
    "                        if dev<0.333 or dev>3:\n",
    "                            continue\n",
    "                    count_DP+=1\n",
    "                \n",
    "    if count_DP==0:\n",
    "        f4+=1\n",
    "        continue\n",
    "    \n",
    "    #remove all variants overlapping with known C57BL/6J and 129S1/SvIMJ SNPs \n",
    "    if str(record.CHROM)+'_'+str(record.POS) in IMJ:\n",
    "        f5+=1\n",
    "        continue\n",
    "        \n",
    "    passed+=1\n",
    "\n",
    "    #print out mice to their corresponding files\n",
    "    for i in miceIDs:\n",
    "        if not record.genotype(i)==None and not record.genotype(i)['GT']==None:\n",
    "            if record.genotype(i)['GT']=='0/1':\n",
    "                outfile=printIDs[miceIDs.index(i)]\n",
    "                outfile.write_record(record)\n",
    "                p[miceIDs.index(i)]+=1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "for i in printIDs:\n",
    "    i.close()\n",
    "    \n",
    "print('all','GATK','shared','<50%GT','badDP','129var','passed',sep='\\t')   \n",
    "print(counter,f1,f2,f3,f4,f5,passed,sep='\\t')\n",
    "print('MF5L1','MF5L5','MF5L6','MF5L9','MF5L10','MF5L12','MF5L13','MF5L22',sep='\\t')\n",
    "print('\\t'.join(map(str,p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTER 2** removes variants that are <=200bp apart within each mouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RemoveVariantsWithin200bp(FileName,OutFile):\n",
    "    '''Removes variants that are closer than 200 bp to each other'''\n",
    "    \n",
    "    input=open(FileName)\n",
    "    outfile=open(OutFile,'w')\n",
    "    \n",
    "    header=input.readline().rstrip()\n",
    "    print(header,file=outfile)\n",
    "\n",
    "    chr=''\n",
    "    pos=0\n",
    "    removed_pos=0\n",
    "    rows=[]\n",
    "    counter=0\n",
    "    passed=0\n",
    "\n",
    "    for line in input:\n",
    "        counter+=1\n",
    "        line=line.rstrip()\n",
    "        row=line.split('\\t')\n",
    "        if not row[0]==chr:\n",
    "            chr=row[0]\n",
    "            pos=int(row[1])\n",
    "            rows.append(line)\n",
    "            removed_pos=0\n",
    "            continue\n",
    "        else:\n",
    "            if int(row[1])-removed_pos <= 200:\n",
    "                    removed_pos=int(row[1])\n",
    "                    continue\n",
    "            else:\n",
    "                if int(row[1])-pos <= 200:\n",
    "                    rows.pop()\n",
    "                    removed_pos=int(row[1])\n",
    "                    continue\n",
    "                else:\n",
    "                    pos=int(row[1])\n",
    "                    rows.append(line)\n",
    "                    continue\n",
    "\n",
    "    for line in rows:\n",
    "        passed+=1\n",
    "        print(line,file=outfile)\n",
    "\n",
    "    #for stats, this is the number discarded  variants\n",
    "    print('all','passed',sep='\\t')   \n",
    "    print(counter,passed,sep='\\t')\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tpassed\n",
      "291\t200\n",
      "all\tpassed\n",
      "164\t152\n",
      "all\tpassed\n",
      "393\t293\n",
      "all\tpassed\n",
      "597\t439\n",
      "all\tpassed\n",
      "288\t231\n",
      "all\tpassed\n",
      "232\t218\n",
      "all\tpassed\n",
      "240\t188\n",
      "all\tpassed\n",
      "327\t274\n"
     ]
    }
   ],
   "source": [
    "RemoveVariantsWithin200bp('MF5L1_filter1.vcf','MF5L1_filter2.vcf')\n",
    "RemoveVariantsWithin200bp('MF5L5_filter1.vcf','MF5L5_filter2.vcf')\n",
    "RemoveVariantsWithin200bp('MF5L6_filter1.vcf','MF5L6_filter2.vcf')\n",
    "RemoveVariantsWithin200bp('MF5L9_filter1.vcf','MF5L9_filter2.vcf')\n",
    "RemoveVariantsWithin200bp('MF5L10_filter1.vcf','MF5L10_filter2.vcf')\n",
    "RemoveVariantsWithin200bp('MF5L12_filter1.vcf','MF5L12_filter2.vcf')\n",
    "RemoveVariantsWithin200bp('MF5L13_filter1.vcf','MF5L13_filter2.vcf')\n",
    "RemoveVariantsWithin200bp('MF5L22_filter1.vcf','MF5L22_filter2.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FilterCodingVariants(FileName,OutFile):\n",
    "    '''This generator will use the Annovar annotation done above to filter\n",
    "    out variants within coding region and display them on screen'''\n",
    "\n",
    "    input=open(FileName)\n",
    "    outfile=open(OutFile,'w')\n",
    "    types={'nonsynonymous_SNV':0,'stopgain':0,\n",
    "          'stoploss':0,'splicing':0}\n",
    "    counter=0\n",
    "    passed=0\n",
    "\n",
    "    for line in input:\n",
    "        counter+=1\n",
    "        type=''\n",
    "        OK=0\n",
    "        line=line.rstrip()\n",
    "        row=line.split('\\t')\n",
    "        info=row[7].split(';')\n",
    "        for i in info:\n",
    "            if i.startswith('AnnovarGene'):\n",
    "                gene=i.split('=')[1].split(':')[0]\n",
    "            if i.startswith('AnnovarType'):\n",
    "                type=i.split('=')[1]\n",
    "                if type in types:\n",
    "                    OK=1\n",
    "                    passed+=1\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            if OK==1:    \n",
    "                print(line,file=outfile)\n",
    "                print(row[0],row[1],row[3],row[4],row[9].split(':')[1],row[10].split(':')[1],row[11].split(':')[1], type,gene,sep='\\t')\n",
    "\n",
    "    print('\\nall','passed',sep='\\t')   \n",
    "    print(counter,passed,'\\n',sep='\\t')\n",
    "    outfile.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t70509665\tG\tC\t31,23\t81,0\t81,0\tnonsynonymous_SNV\tErich2\n",
      "7\t14225894\tT\tC\t94,46\t114,0\t181,28\tnonsynonymous_SNV\tSult2a6\n",
      "7\t15940142\tT\tC\t7,10\t32,0\t29,0\tnonsynonymous_SNV\tGltscr2\n",
      "7\t85754889\tA\tT\t81,36\t45,0\t138,25\tnonsynonymous_SNV\tVmn2r72\n",
      "8\t108949251\tA\tG\t55,20\t59,0\t47,0\tnonsynonymous_SNV\tZfhx3\n",
      "12\t110977486\tG\tA\t5,6\t46,0\t38,0\tnonsynonymous_SNV\tAnkrd9\n",
      "17\t25722876\tT\tA\t37,40\t83,0\t91,0\tnonsynonymous_SNV\tChtf18\n",
      "\n",
      "all\tpassed\n",
      "201\t7\t\n",
      "\n",
      "3\t99352190\tA\tG\t143,0\t89,109\t152,0\tnonsynonymous_SNV\tTbx15\n",
      "3\t135228816\tT\tA\t18,0\t7,8\t20,0\tnonsynonymous_SNV\tCenpe\n",
      "6\t35080128\tG\tA\t46,0\t23,18\t55,0\tnonsynonymous_SNV\tCnot4\n",
      "8\t70913530\tA\tT\t52,0\t67,43\t121,0\tnonsynonymous_SNV\tMap1s\n",
      "17\t70657633\tT\tG\t35,0\t11,22\t21,0\tsplicing\tDlgap1(NM_027712\n",
      "\n",
      "all\tpassed\n",
      "153\t5\t\n",
      "\n",
      "1\t82741945\tC\tA\t106,1\t127,2\t34,56\tnonsynonymous_SNV\tMff\n",
      "2\t67516594\tA\tG\t137,0\t141,0\t92,80\tnonsynonymous_SNV\tXirp2\n",
      "2\t76724952\tG\tA\t35,0\t47,0\t27,20\tnonsynonymous_SNV\tTtn\n",
      "2\t76939280\tT\tA\t58,0\t56,0\t41,29\tnonsynonymous_SNV\tTtn\n",
      "2\t88423385\tA\tT\t114,0\t101,0\t74,65\tnonsynonymous_SNV\tOlfr1181\n",
      "2\t111537791\tA\tT\t123,0\t126,0\t79,72\tnonsynonymous_SNV\tOlfr1294\n",
      "2\t140120707\tT\tC\t140,0\t124,0\t79,61\tnonsynonymous_SNV\tEsf1\n",
      "5\t108650355\tC\tT\t105,0\t135,0\t49,54\tnonsynonymous_SNV\tDgkq\n",
      "7\t79822260\tA\tC\t19,0\t14,0\t10,6\tnonsynonymous_SNV\tAnpep\n",
      "7\t101990583\tA\tT\t31,0\t42,0\t23,29\tstopgain\tNuma1\n",
      "\n",
      "all\tpassed\n",
      "294\t10\t\n",
      "\n",
      "1\t33746762\tT\tG\t63,0\t101,0\t85,0\tnonsynonymous_SNV\tBag2\n",
      "1\t36163249\tT\tC\t67,0\t34,0\t82,0\tnonsynonymous_SNV\tUggt1\n",
      "1\t40125203\tA\tG\t26,0\t34,0\t34,0\tnonsynonymous_SNV\tIl1r2\n",
      "2\t76549471\tA\tC\t76,0\t71,0\t77,0\tnonsynonymous_SNV\tOsbpl6\n",
      "2\t112407616\tG\tA\t58,0\t33,0\t79,0\tnonsynonymous_SNV\tKatnbl1\n",
      "2\t112630022\tA\tG\t104,0\t114,0\t109,0\tnonsynonymous_SNV\tAven\n",
      "2\t153136757\tG\tA\t18,0\t23,0\t29,0\tnonsynonymous_SNV\tHck\n",
      "2\t153225070\tT\tA\t36,0\t61,0\t39,0\tnonsynonymous_SNV\tTspyl3\n",
      "9\t123712602\tT\tG\t76,0\t69,0\t104,0\tnonsynonymous_SNV\tLztfl1\n",
      "10\t12711476\tC\tA\t73,0\t94,0\t87,0\tnonsynonymous_SNV\tUtrn\n",
      "10\t128290865\tC\tT\t41,0\t40,0\t44,0\tstopgain\tStat2\n",
      "11\t52145503\tT\tC\t166,0\t178,0\t238,0\tnonsynonymous_SNV\tOlfr1373\n",
      "11\t69129597\tA\tG\t121,0\t182,0\t150,0\tnonsynonymous_SNV\tAloxe3\n",
      "14\t8169757\tA\tG\t46,0\t40,0\t65,0\tnonsynonymous_SNV\tPdhb\n",
      "15\t89456795\tG\tT\t94,0\t93,0\t88,0\tstopgain\tMapk8ip2\n",
      "16\t59554543\tC\tT\t150,0\t201,0\t188,0\tnonsynonymous_SNV\tCrybg3\n",
      "17\t12271353\tT\tA\t97,0\t178,0\t112,0\tnonsynonymous_SNV\tMap3k4\n",
      "17\t45416968\tT\tA\t91,0\t73,0\t120,0\tstopgain\tCdc5l\n",
      "19\t39563826\tC\tT\t106,0\t146,0\t162,0\tnonsynonymous_SNV\tCyp2c39\n",
      "19\t46065668\tC\tG\t126,0\t181,0\t178,0\tnonsynonymous_SNV\tPprc1\n",
      "\n",
      "all\tpassed\n",
      "440\t20\t\n",
      "\n",
      "2\t101696795\tC\tT\t103,0\t143,0\t123,0\tnonsynonymous_SNV\tTraf6\n",
      "7\t82868974\tG\tA\t63,0\t105,0\t87,0\tnonsynonymous_SNV\tMex3b\n",
      "9\t21634876\tT\tC\t64,0\t57,0\t76,0\tnonsynonymous_SNV\tSmarca4\n",
      "10\t67538372\tT\tC\t152,0\t195,0\t183,0\tnonsynonymous_SNV\tEgr2\n",
      "18\t71327504\tC\tT\t71,0\t74,0\t76,0\tnonsynonymous_SNV\tDcc\n",
      "19\t56810315\tG\tT\t34,0\t23,0\t46,0\tstopgain\tA630007B06Rik\n",
      "\n",
      "all\tpassed\n",
      "232\t6\t\n",
      "\n",
      "2\t30086662\tA\tG\t152,0\t152,0\t126,0\tnonsynonymous_SNV\tPkn3\n",
      "2\t40874986\tG\tT\t91,0\t68,0\t127,0\tnonsynonymous_SNV\tLrp1b\n",
      "2\t61804747\tT\tC\t55,0\t67,0\t70,0\tnonsynonymous_SNV\tTbr1\n",
      "2\t144572561\tG\tA\t61,0\t50,0\t80,0\tnonsynonymous_SNV\tSec23b\n",
      "4\t141581029\tA\tG\t116,0\t129,0\t103,0\tnonsynonymous_SNV\tFblim1\n",
      "5\t123760656\tT\tA\t112,0\t68,0\t113,0\tstopgain\tKntc1\n",
      "5\t136373331\tT\tC\t65,0\t70,0\t65,0\tnonsynonymous_SNV\tCux1\n",
      "9\t123963447\tG\tT\t17,0\t25,0\t34,0\tnonsynonymous_SNV\tCcr1\n",
      "10\t84958016\tA\tG\t88,0\t110,0\t100,0\tnonsynonymous_SNV\tRic8b\n",
      "11\t57221033\tA\tT\t66,0\t86,0\t78,0\tnonsynonymous_SNV\tGria1\n",
      "11\t101740781\tT\tG\t34,0\t68,0\t38,0\tnonsynonymous_SNV\tDhx8\n",
      "13\t112368238\tG\tA\t43,0\t73,0\t48,0\tstopgain\tAnkrd55\n",
      "14\t32966414\tA\tG\t106,0\t141,0\t118,0\tnonsynonymous_SNV\tWdfy4\n",
      "16\t92605854\tT\tC\t16,0\t32,0\t29,0\tnonsynonymous_SNV\tRunx1\n",
      "\n",
      "all\tpassed\n",
      "219\t14\t\n",
      "\n",
      "5\t86719746\tT\tA\t88,0\t64,0\t126,0\tnonsynonymous_SNV\tTmprss11e\n",
      "6\t129517379\tA\tG\t40,0\t59,0\t49,0\tnonsynonymous_SNV\tTmem52b\n",
      "6\t148237808\tG\tA\t102,0\t126,0\t92,0\tnonsynonymous_SNV\tTmtc1\n",
      "7\t141620530\tG\tA\t100,0\t132,0\t112,0\tnonsynonymous_SNV\tAp2a2\n",
      "11\t20077297\tG\tC\t120,0\t116,0\t137,0\tnonsynonymous_SNV\tActr2\n",
      "11\t67921730\tC\tT\t19,0\t27,0\t18,0\tnonsynonymous_SNV\tUsp43\n",
      "13\t100285719\tC\tT\t169,0\t111,0\t255,0\tnonsynonymous_SNV\tNaip7\n",
      "\n",
      "all\tpassed\n",
      "189\t7\t\n",
      "\n",
      "6\t36523684\tA\tG\t132,0\t170,0\t154,0\tnonsynonymous_SNV\tChrm2\n",
      "8\t70259804\tG\tA\t86,0\t150,0\t104,0\tnonsynonymous_SNV\tSugp2\n",
      "10\t77260815\tT\tC\t59,0\t82,0\t79,0\tnonsynonymous_SNV\tPofut2\n",
      "10\t114800967\tT\tC\t2,0\t20,0\t22,0\tnonsynonymous_SNV\tTrhde\n",
      "10\t117278121\tT\tC\t81,0\t101,0\t96,0\tstoploss\tLyz2\n",
      "11\t60710357\tG\tA\t72,0\t119,0\t68,0\tnonsynonymous_SNV\tLlgl1\n",
      "13\t34896062\tT\tA\t56,0\t44,0\t97,0\tstopgain\tPrpf4b\n",
      "13\t61568333\tA\tT\t133,0\t82,0\t207,0\tnonsynonymous_SNV\tCts3\n",
      "13\t90898831\tG\tA\t34,0\t22,0\t21,0\tnonsynonymous_SNV\tAtp6ap1l\n",
      "13\t94443934\tG\tA\t108,0\t133,0\t116,0\tnonsynonymous_SNV\tAp3b1\n",
      "15\t6786636\tC\tT\t101,0\t104,0\t109,0\tstopgain\tRictor\n",
      "\n",
      "all\tpassed\n",
      "275\t11\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FilterCodingVariants('MF5L1_filter2.vcf','MF5L1_filter3.vcf')\n",
    "FilterCodingVariants('MF5L5_filter2.vcf','MF5L5_filter3.vcf')\n",
    "FilterCodingVariants('MF5L6_filter2.vcf','MF5L6_filter3.vcf')\n",
    "FilterCodingVariants('MF5L9_filter2.vcf','MF5L9_filter3.vcf')\n",
    "FilterCodingVariants('MF5L10_filter2.vcf','MF5L10_filter3.vcf')\n",
    "FilterCodingVariants('MF5L12_filter2.vcf','MF5L12_filter3.vcf')\n",
    "FilterCodingVariants('MF5L13_filter2.vcf','MF5L13_filter3.vcf')\n",
    "FilterCodingVariants('MF5L22_filter2.vcf','MF5L22_filter3.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
